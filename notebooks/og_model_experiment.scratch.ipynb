{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6ea81cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91b6fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1a4250f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available?        True\n",
      "CUDA version:          12.8\n",
      "Number of GPUs:        1\n",
      "Current GPU:          NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available?       \", torch.cuda.is_available())\n",
    "print(\"CUDA version:         \", torch.version.cuda)\n",
    "print(\"Number of GPUs:       \", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Current GPU:         \", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14a42e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jon/Documents/codespace/projects/semantic_domain_for_biblical_greek/.venv/lib/python3.12/site-packages/stringcase.py:247: SyntaxWarning: invalid escape sequence '\\W'\n",
      "  return re.sub(\"\\W+\", \"\", string)\n",
      "/home/jon/Documents/codespace/projects/semantic_domain_for_biblical_greek/.venv/lib/python3.12/site-packages/cltk/alphabet/lat.py:166: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfetch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FetchCorpus\n\u001b[32m      2\u001b[39m corpus_downloader = FetchCorpus(language=\u001b[33m\"\u001b[39m\u001b[33mgrc\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# grc = ancient Greek\u001b[39;00m\n\u001b[32m      3\u001b[39m corpus_downloader.import_corpus(\u001b[33m\"\u001b[39m\u001b[33mgrc_models_cltk\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codespace/projects/semantic_domain_for_biblical_greek/.venv/lib/python3.12/site-packages/cltk/__init__.py:5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"Init module for importing the CLTK class.\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m metadata\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnlp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NLP\n\u001b[32m      7\u001b[39m curr_version: \u001b[38;5;28mstr\u001b[39m = metadata.version(\u001b[33m\"\u001b[39m\u001b[33mcltk\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m __version__: \u001b[38;5;28mstr\u001b[39m = curr_version\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codespace/projects/semantic_domain_for_biblical_greek/.venv/lib/python3.12/site-packages/cltk/nlp.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_types\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Doc, Language, Pipeline, Process\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UnimplementedAlgorithmError\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlanguages\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipelines\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     AkkadianPipeline,\n\u001b[32m     11\u001b[39m     ArabicPipeline,\n\u001b[32m     12\u001b[39m     AramaicPipeline,\n\u001b[32m     13\u001b[39m     ChinesePipeline,\n\u001b[32m     14\u001b[39m     CopticPipeline,\n\u001b[32m     15\u001b[39m     GothicPipeline,\n\u001b[32m     16\u001b[39m     GreekPipeline,\n\u001b[32m     17\u001b[39m     HindiPipeline,\n\u001b[32m     18\u001b[39m     LatinPipeline,\n\u001b[32m     19\u001b[39m     MiddleEnglishPipeline,\n\u001b[32m     20\u001b[39m     MiddleFrenchPipeline,\n\u001b[32m     21\u001b[39m     MiddleHighGermanPipeline,\n\u001b[32m     22\u001b[39m     OCSPipeline,\n\u001b[32m     23\u001b[39m     OldEnglishPipeline,\n\u001b[32m     24\u001b[39m     OldFrenchPipeline,\n\u001b[32m     25\u001b[39m     OldNorsePipeline,\n\u001b[32m     26\u001b[39m     PaliPipeline,\n\u001b[32m     27\u001b[39m     PanjabiPipeline,\n\u001b[32m     28\u001b[39m     SanskritPipeline,\n\u001b[32m     29\u001b[39m )\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlanguages\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_lang\n\u001b[32m     32\u001b[39m iso_to_pipeline = {\n\u001b[32m     33\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33makk\u001b[39m\u001b[33m\"\u001b[39m: AkkadianPipeline,\n\u001b[32m     34\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mang\u001b[39m\u001b[33m\"\u001b[39m: OldEnglishPipeline,\n\u001b[32m   (...)\u001b[39m\u001b[32m     51\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msan\u001b[39m\u001b[33m\"\u001b[39m: SanskritPipeline,\n\u001b[32m     52\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codespace/projects/semantic_domain_for_biblical_greek/.venv/lib/python3.12/site-packages/cltk/languages/pipelines.py:14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malphabet\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprocesses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GreekNormalizeProcess, LatinNormalizeProcess\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_types\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Language, Pipeline, Process\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdependency\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprocesses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     15\u001b[39m     ChineseStanzaProcess,\n\u001b[32m     16\u001b[39m     CopticStanzaProcess,\n\u001b[32m     17\u001b[39m     GothicStanzaProcess,\n\u001b[32m     18\u001b[39m     GreekStanzaProcess,\n\u001b[32m     19\u001b[39m     LatinSpacyProcess,\n\u001b[32m     20\u001b[39m     LatinStanzaProcess,\n\u001b[32m     21\u001b[39m     OCSStanzaProcess,\n\u001b[32m     22\u001b[39m     OldFrenchStanzaProcess,\n\u001b[32m     23\u001b[39m )\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membeddings\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprocesses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     25\u001b[39m     ArabicEmbeddingsProcess,\n\u001b[32m     26\u001b[39m     AramaicEmbeddingsProcess,\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m     SanskritEmbeddingsProcess,\n\u001b[32m     34\u001b[39m )\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlanguages\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_lang\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codespace/projects/semantic_domain_for_biblical_greek/.venv/lib/python3.12/site-packages/cltk/dependency/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"Init for ``cltk.dependency``.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprocesses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codespace/projects/semantic_domain_for_biblical_greek/.venv/lib/python3.12/site-packages/cltk/dependency/processes.py:7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdataclasses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dataclass\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Literal, Optional\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspacy\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstanza\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mboltons\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcacheutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cachedproperty\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codespace/projects/semantic_domain_for_biblical_greek/.venv/lib/python3.12/site-packages/spacy/__init__.py:6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, Iterable, Union\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# set library-specific custom warning handling before doing anything else\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m setup_default_warnings\n\u001b[32m      8\u001b[39m setup_default_warnings()  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# These are imported as part of the API\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codespace/projects/semantic_domain_for_biblical_greek/.venv/lib/python3.12/site-packages/spacy/errors.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Literal\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mErrorsWithCodes\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m):\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, code):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codespace/projects/semantic_domain_for_biblical_greek/.venv/lib/python3.12/site-packages/spacy/compat.py:39\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcatalogue\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _importlib_metadata \u001b[38;5;28;01mas\u001b[39;00m importlib_metadata  \u001b[38;5;66;03m# type: ignore[no-redef]    # noqa: F401\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mthinc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optimizer  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     41\u001b[39m pickle = pickle\n\u001b[32m     42\u001b[39m copy_reg = copy_reg\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codespace/projects/semantic_domain_for_biblical_greek/.venv/lib/python3.12/site-packages/thinc/api.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     CupyOps,\n\u001b[32m      3\u001b[39m     MPSOps,\n\u001b[32m      4\u001b[39m     NumpyOps,\n\u001b[32m      5\u001b[39m     Ops,\n\u001b[32m      6\u001b[39m     get_current_ops,\n\u001b[32m      7\u001b[39m     get_ops,\n\u001b[32m      8\u001b[39m     set_current_ops,\n\u001b[32m      9\u001b[39m     set_gpu_allocator,\n\u001b[32m     10\u001b[39m     use_ops,\n\u001b[32m     11\u001b[39m     use_pytorch_for_gpu_memory,\n\u001b[32m     12\u001b[39m     use_tensorflow_for_gpu_memory,\n\u001b[32m     13\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m enable_mxnet, enable_tensorflow, has_cupy\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Config, ConfigValidationError, registry\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codespace/projects/semantic_domain_for_biblical_greek/.venv/lib/python3.12/site-packages/thinc/backends/__init__.py:17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_cupy_allocators\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cupy_pytorch_allocator, cupy_tensorflow_allocator\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_param_server\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParamServer\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcupy_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CupyOps\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmps_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MPSOps\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnumpy_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NumpyOps\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codespace/projects/semantic_domain_for_biblical_greek/.venv/lib/python3.12/site-packages/thinc/backends/cupy_ops.py:16\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      7\u001b[39m     is_cupy_array,\n\u001b[32m      8\u001b[39m     is_mxnet_gpu_array,\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m     torch2xp,\n\u001b[32m     14\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _custom_kernels\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnumpy_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NumpyOps\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Ops\n\u001b[32m     20\u001b[39m \u001b[38;5;129m@registry\u001b[39m.ops(\u001b[33m\"\u001b[39m\u001b[33mCupyOps\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mCupyOps\u001b[39;00m(Ops):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/codespace/projects/semantic_domain_for_biblical_greek/.venv/lib/python3.12/site-packages/thinc/backends/numpy_ops.pyx:1\u001b[39m, in \u001b[36minit thinc.backends.numpy_ops\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "from cltk.data.fetch import FetchCorpus\n",
    "corpus_downloader = FetchCorpus(language=\"grc\")  # grc = ancient Greek\n",
    "corpus_downloader.import_corpus(\"grc_models_cltk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17742743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/5, Average Loss: 7.5845\n",
      "Epoch 2/5, Average Loss: 5.8092\n",
      "Epoch 3/5, Average Loss: 4.7247\n",
      "Epoch 4/5, Average Loss: 4.0308\n",
      "Epoch 5/5, Average Loss: 3.5785\n",
      "Embedding for 'θεος': [ 0.32356393 -0.55579644 -0.18890837 -0.7147516   0.08426335 -0.38437507\n",
      "  0.49991208 -0.57248574 -0.7918278  -0.22177766]...\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "file_path = 'data/combined_text.txt'\n",
    "\n",
    "# Read and preprocess the text\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Preprocess: lowercase, remove non-Greek characters (keeping Greek letters and spaces),\n",
    "# then split into words.\n",
    "text = text.lower()\n",
    "text = re.sub(r'[^\\u0370-\\u03ff\\s]', '', text)  # Keep Greek Unicode range\n",
    "words = re.split(r'\\s+', text.strip())\n",
    "\n",
    "# Build vocabulary and word frequencies\n",
    "word_counts = Counter(words)\n",
    "vocab = sorted(word_counts.keys())\n",
    "vocab_size = len(vocab)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "ix_to_word = {i: word for word, i in word_to_ix.items()}\n",
    "\n",
    "# Prepare unigram distribution for negative sampling (raised to 0.75 power)\n",
    "freq = np.array([word_counts[word] for word in vocab]) ** 0.75\n",
    "prob = freq / freq.sum()\n",
    "\n",
    "# Generate skip-gram pairs (center word as target, surrounding as context)\n",
    "def generate_pairs(words, window_size=2):\n",
    "    pairs = []\n",
    "    for i in range(len(words)):\n",
    "        for j in range(1, window_size + 1):\n",
    "            if i - j >= 0:\n",
    "                pairs.append((word_to_ix[words[i]], word_to_ix[words[i - j]]))\n",
    "            if i + j < len(words):\n",
    "                pairs.append((word_to_ix[words[i]], word_to_ix[words[i + j]]))\n",
    "    return pairs\n",
    "\n",
    "pairs = generate_pairs(words)\n",
    "\n",
    "# Skip-Gram model with negative sampling\n",
    "class SkipGramNeg(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super(SkipGramNeg, self).__init__()\n",
    "        self.in_embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.out_embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        # Initialize embeddings\n",
    "        self.in_embed.weight.data.uniform_(-1, 1)\n",
    "        self.out_embed.weight.data.uniform_(-1, 1)\n",
    "\n",
    "    def forward(self, target, context, noise):\n",
    "        emb_t = self.in_embed(target)  # (batch_size, embed_dim)\n",
    "        emb_c = self.out_embed(context)  # (batch_size, embed_dim)\n",
    "        emb_n = self.out_embed(noise)  # (batch_size, num_neg, embed_dim)\n",
    "        \n",
    "        # Positive score: dot product\n",
    "        score = torch.sum(emb_t * emb_c, dim=1)  # (batch_size)\n",
    "        \n",
    "        # Negative scores: dot products\n",
    "        neg_score = torch.sum(emb_t.unsqueeze(1) * emb_n, dim=2)  # (batch_size, num_neg)\n",
    "        \n",
    "        return score, neg_score\n",
    "\n",
    "# Training parameters\n",
    "embed_dim = 100  # Embedding dimension (adjust as needed)\n",
    "num_neg = 5  # Number of negative samples per positive\n",
    "batch_size = 512  # Batch size\n",
    "epochs = 5  # Number of epochs (increase for better results)\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize model, optimizer\n",
    "model = SkipGramNeg(vocab_size, embed_dim).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Batch generator\n",
    "def generate_batches(pairs, batch_size):\n",
    "    for i in range(0, len(pairs), batch_size):\n",
    "        yield pairs[i:i + batch_size]\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    for batch in generate_batches(pairs, batch_size):\n",
    "        if len(batch) == 0:\n",
    "            continue\n",
    "        targets = torch.tensor([p[0] for p in batch], dtype=torch.long).to(device)\n",
    "        contexts = torch.tensor([p[1] for p in batch], dtype=torch.long).to(device)\n",
    "        noises   = torch.tensor(np.random.choice(vocab_size, size=(len(batch), num_neg), p=prob), \n",
    "                        dtype=torch.long).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        score, neg_score = model(targets, contexts, noises)\n",
    "        \n",
    "        # Loss calculation (negative log likelihood)\n",
    "        pos_loss = torch.log(torch.sigmoid(score))\n",
    "        neg_loss = torch.sum(torch.log(torch.sigmoid(-neg_score)), dim=1)\n",
    "        loss = -torch.mean(pos_loss + neg_loss)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "    \n",
    "    avg_loss = total_loss / num_batches if num_batches > 0 else 0\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# After training, the input embeddings are the word vectors\n",
    "embeddings = model.in_embed.weight.data.cpu().numpy()\n",
    "\n",
    "# Example: Get embedding for a word (replace 'θεος' with an actual Greek word from your vocab)\n",
    "example_word = 'θεος'  # Greek for 'God'\n",
    "if example_word in word_to_ix:\n",
    "    word_idx = word_to_ix[example_word]\n",
    "    word_embedding = embeddings[word_idx]\n",
    "    print(f\"Embedding for '{example_word}': {word_embedding[:10]}...\")  # Print first 10 dimensions\n",
    "else:\n",
    "    print(f\"'{example_word}' not in vocabulary.\")\n",
    "\n",
    "# To save embeddings\n",
    "np.save('greek_nt_embeddings.npy', embeddings)\n",
    "with open('vocab.txt', 'w', encoding='utf-8') as f:\n",
    "    for word in vocab:\n",
    "        f.write(word + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "631c3a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to θεός (God):\n",
      "  μηδ          0.4098\n",
      "  πίνουσιν     0.3933\n",
      "  ξελθόντος    0.3762\n",
      "  παιδίσκην    0.3754\n",
      "\n",
      "Most similar to ιησους (Jesus):\n",
      "Warning: 'ιησους' not found in vocabulary.\n",
      "\n",
      "Most similar to πνευμα (spirit):\n",
      "Warning: 'πνευμα' not found in vocabulary.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Load\n",
    "embeddings = np.load('greek_nt_embeddings.npy')\n",
    "with open('vocab.txt', encoding='utf-8') as f:\n",
    "    vocab = [line.strip() for line in f]\n",
    "word_to_ix = {w: i for i, w in enumerate(vocab)}\n",
    "\n",
    "def most_similar(word, topn=4):\n",
    "    if word not in word_to_ix:\n",
    "        # Return an empty list so the loop just skips it, \n",
    "        # or [(f\"'{word}' not found\", 0.0)] to show an error in the loop\n",
    "        print(f\"Warning: '{word}' not found in vocabulary.\")\n",
    "        return [] \n",
    "    \n",
    "    vec = embeddings[word_to_ix[word]]\n",
    "    sims = [1 - cosine(vec, embeddings[i]) for i in range(len(embeddings))]\n",
    "    \n",
    "    most_sim_idx = np.argsort(sims)[::-1][1:topn+1]\n",
    "    return [(vocab[i], sims[i]) for i in most_sim_idx]\n",
    "\n",
    "# Try some theologically interesting words\n",
    "print(\"Most similar to θεός (God):\")\n",
    "for w, sim in most_similar('θεος'):\n",
    "    print(f\"  {w:12} {sim:.4f}\")\n",
    "\n",
    "print(\"\\nMost similar to ιησους (Jesus):\")\n",
    "for w, sim in most_similar('ιησους'):\n",
    "    print(f\"  {w:12} {sim:.4f}\")\n",
    "\n",
    "print(\"\\nMost similar to πνευμα (spirit):\")\n",
    "for w, sim in most_similar('πνευμα'):\n",
    "    print(f\"  {w:12} {sim:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic-domain-for-biblical-greek",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
